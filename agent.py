import json
import logging
import asyncio
import re
from datetime import datetime
from dotenv import load_dotenv

from livekit import agents
from livekit.agents import AgentSession, Agent, RoomInputOptions, ChatContext
from livekit.plugins import google
from prompts import AGENT_INSTRUCTION, SESSION_INSTRUCTION, SENTENCES_TEACHING_PROMPT, ENGLISH_CONVERSATION_PROMPT
from tools import get_weather, search_web, send_email
from supabase_client import supabase_manager
# from sentences import get_sentences_prompt  # ØªÙ… Ù†Ù‚Ù„ prompt Ø¥Ù„Ù‰ prompts.py

load_dotenv()

# ØªÙ‚Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù„ÙˆØ¬ Ù„ØªØ¬Ù†Ø¨ Ø±Ø³Ø§Ø¦Ù„ transcription ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
logging.getLogger("livekit").setLevel(logging.WARNING)


class Assistant(Agent):
    def __init__(self, chat_ctx: ChatContext = None, user_id: str = None, user_name: str = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", mode: str = "normal", voice_name: str = "Aoede") -> None:
        """
        Ù…Ø¹Ù„Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        
        Args:
            voice_name: Ø§Ø³Ù… Ø§Ù„ØµÙˆØª (Aoede Ø£Ùˆ Kore Ù„Ù„Ø£Ù†Ø«Ù‰ØŒ Puck Ø£Ùˆ Charon Ø£Ùˆ Fenrir Ù„Ù„Ø°ÙƒØ±)
        """
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶Ø¹
        if mode == "sentences_learning":
            instructions = SENTENCES_TEACHING_PROMPT
            print(f"[agent] Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©")
        elif mode == "english_conversation":
            # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ prompt Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª
            self.base_conversation_prompt = ENGLISH_CONVERSATION_PROMPT
            instructions = ENGLISH_CONVERSATION_PROMPT.replace("{podcast_memory}", "")
            print(f"[agent] Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
        else:
            instructions = AGENT_INSTRUCTION
            print(f"[agent] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØµÙˆØª
        valid_voices = ["Aoede", "Kore", "Puck", "Charon", "Fenrir"]
        if voice_name not in valid_voices:
            print(f"âš ï¸ ØµÙˆØª ØºÙŠØ± ØµØ§Ù„Ø­: {voice_name}. Ø§Ø³ØªØ®Ø¯Ø§Ù… Aoede")
            voice_name = "Aoede"
        
        print(f"ğŸ¤ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØª: {voice_name}")
            
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø¨Ø¯ÙˆÙ† speech_config
        super().__init__(
            chat_ctx=chat_ctx,
            instructions=instructions,
            llm=google.beta.realtime.RealtimeModel(
                voice=voice_name,
                temperature=0.8,
            ),
            tools=[
                get_weather,
                search_web,
                send_email
            ],
        )
        self.voice_name = voice_name
        self.mode = mode
        self.user_id = user_id
        self.user_name = user_name
        self.user_progress = None
        self.personal_context = None  # Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        self._last_context_save = None  # Ù„Ù„Ù€ rate limiting
        
        # ğŸ¯ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        self.level_assessment = None  # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªÙˆÙ‰
        self.achievements = None  # Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª
        self.session_start_time = datetime.now()  # ÙˆÙ‚Øª Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©
        self.words_learned_session = []  # ÙƒÙ„Ù…Ø§Øª Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù„Ø³Ø©
        self.session_correct_answers = 0
        self.session_total_attempts = 0
        
        self.session_data = {
            "session_id": str(datetime.now().timestamp()),
            "start_time": datetime.now().isoformat(),
            "words_discussed": [],
            "topics_covered": [],
            "current_topic": "",
            "last_position": ""
        }
        self._message_count = 0
        
        # ğŸ“š Ù…ØªØºÙŠØ±Ø§Øª ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ - ØªÙ‡ÙŠØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ØªØ¬Ù†Ø¨ AttributeError
        self.sentences_session_id = f"sentences_{int(datetime.now().timestamp())}"
        self.sentences_progress = None
        self.current_sentences = []
        self.sentences_completed = 0
        self.current_level = 1
        self.current_sentence_index = 0
        self.learned_sentences_history = []
        
        # Ø³ÙŠØªÙ… Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù…Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø©
    
    async def load_sentences_progress(self):
        """ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ ÙˆØ¯Ù…Ø¬Ù‡ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        if not self.user_id or self.mode != "sentences_learning":
            return
            
        try:
            # Ø¬Ù„Ø¨ Ø¢Ø®Ø± Ø¬Ù„Ø³Ø© Ù†Ø´Ø·Ø© Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯Ø©
            self.sentences_progress = await supabase_manager.get_sentences_progress(self.user_id)
            
            if not self.sentences_progress:
                # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©
                result = await supabase_manager.create_sentences_session(
                    self.user_id, 
                    self.sentences_session_id
                )
                self.sentences_progress = result.get("data")
                
                # âœ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù„Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                self.current_sentences = []
                self.sentences_completed = 0
                self.current_level = 1
                self.current_sentence_index = 0
                self.learned_sentences_history = []
                
                print(f"[agent] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©: {self.sentences_session_id}")
            else:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù‚ÙˆØ¬ÙˆØ¯Ø©
                self.sentences_session_id = self.sentences_progress["session_id"]
                self.current_sentences = self.sentences_progress.get("generated_sentences", [])
                self.sentences_completed = self.sentences_progress.get("completed_sentences", 0)
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆØªØ§Ø±ÙŠØ® Ø§Ù„Ø¬Ù…Ù„
                self.current_level = self.sentences_progress.get("current_level", 1)
                self.learned_sentences_history = self.sentences_progress.get("learned_sentences_history", [])
                # ØªØ­Ø¯ÙŠØ« current_sentence_index Ù„Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ù…Ù† Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© (ÙŠØ´ÙŠØ± Ù„Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©)
                # Ø¥Ø°Ø§ Ø£ÙƒÙ…Ù„ 2 Ø¬Ù…Ù„ØŒ Ø§Ù„Ù…Ø¤Ø´Ø± ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† 2 (Ù„Ù„Ø¬Ù…Ù„Ø© Ø±Ù‚Ù… 3)
                self.current_sentence_index = self.sentences_progress.get("current_sentence_index", self.sentences_completed)
                
                # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† ØºÙŠØ± ØµØ­ÙŠØ­
                current_total = self.sentences_progress.get("total_sentences", 0)
                actual_total = len(self.current_sentences)
                if current_total != actual_total and actual_total > 0:
                    await supabase_manager.update_sentences_progress(
                        self.user_id,
                        self.sentences_session_id,
                        total_sentences=actual_total
                    )
                    self.sentences_progress["total_sentences"] = actual_total
                    print(f"[agent] ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù† {current_total} Ø¥Ù„Ù‰ {actual_total}")
                
                print(f"[agent] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù„Ø³Ø© Ø¬Ù…Ù„ Ù…ÙˆØ¬ÙˆØ¯Ø©: {self.sentences_session_id}")
                print(f"[agent] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙÙƒØªÙ…Ù„Ø©: {self.sentences_completed}, Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: {self.current_sentence_index}")
                print(f"[agent] Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ: {self.current_level}, Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø© ØªØ§Ø±ÙŠØ®ÙŠØ§Ù‹: {len(self.learned_sentences_history)}")
            
            # Ø¯Ù…Ø¬ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            if self.sentences_progress and self.chat_ctx:
                sentences_memory_context = self._build_sentences_memory_context()
                if sentences_memory_context:
                    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØªØ­Ø¯ÙŠØ«Ù‡Ø§
                    new_ctx = self.chat_ctx.copy()
                    new_ctx.add_message(role="system", content=sentences_memory_context)
                    await self.update_chat_ctx(new_ctx)
                    print(f"[agent] ØªÙ… Ø¯Ù…Ø¬ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ù†Ø¬Ø§Ø­")
                
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„: {e}")

    async def save_sentence_progress(self, sentence_text: str, sentence_index: int, completed: bool = False):
        """Ø­ÙØ¸ ØªÙ‚Ø¯Ù… Ø¬Ù…Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©"""
        if not self.user_id or self.mode != "sentences_learning" or not self.sentences_session_id:
            return
            
        try:
            sentence_data = {
                "sentence": sentence_text,
                "completed": completed,
                "timestamp": datetime.now().isoformat(),
                "attempts": 1
            }
            
            await supabase_manager.save_sentences_data(
                self.user_id, 
                self.sentences_session_id, 
                sentence_data, 
                sentence_index
            )
            print(f"[agent] ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„Ø© {sentence_index}")
            
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„Ø©: {e}")

    async def process_sentences_response(self, agent_text: str):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not self.user_id or self.mode != "sentences_learning":
            return
        
        # âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ sentences_session_id Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸
        if not hasattr(self, 'sentences_session_id') or not self.sentences_session_id:
            print(f"[agent] âš ï¸ sentences_session_id ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù„Ù† ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„")
            return
            
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø§Ù„Ù…ÙÙˆÙ„Ø¯Ø© ÙÙŠ Ø§Ù„Ø±Ø¯
            # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø«Ù„: "1. **I am happy.**" Ø£Ùˆ "**I am happy.**"
            sentence_patterns = [
                r'\*\*([A-Z][^*]+\.)\*\*',  # **I am happy.**
                r'[\d]+\.\s*\*\*([A-Z][^*]+\.)\*\*',  # 1. **I am happy.**
                r'"([A-Z][^"]+\.)"',  # "I am happy."
            ]
            
            found_sentences = []
            for pattern in sentence_patterns:
                matches = re.findall(pattern, agent_text)
                found_sentences.extend(matches)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙÙˆÙ„Ø¯Ø© Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª
            if found_sentences:
                # ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                if not hasattr(self, 'current_sentences') or not self.current_sentences:
                    self.current_sentences = []
                
                # Ù…Ù‚Ø§Ø±Ù†Ø© Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø¬Ù…Ù„ - ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù…Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
                normalized_current = [s.lower().replace('.', '').replace(',', '').strip() for s in self.current_sentences]
                
                new_sentences = []
                for sentence in found_sentences:
                    clean_sentence = sentence.strip()
                    normalized_new = clean_sentence.lower().replace('.', '').replace(',', '').strip()
                    
                    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ (Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø¸Ù)
                    if normalized_new not in normalized_current and clean_sentence:
                        new_sentences.append(clean_sentence)
                        normalized_current.append(normalized_new)  # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù„Ø§Ø­Ù‚Ø©
                
                if new_sentences:
                    self.current_sentences.extend(new_sentences)
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ù„Ù… (Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡)
                    if not hasattr(self, 'learned_sentences_history'):
                        self.learned_sentences_history = []
                    self.learned_sentences_history.extend(new_sentences)
                    
                    # Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    await supabase_manager.update_sentences_progress(
                        self.user_id,
                        self.sentences_session_id,
                        generated_sentences=self.current_sentences,
                        total_sentences=len(self.current_sentences),
                        current_level=self.current_level,
                        learned_sentences_history=self.learned_sentences_history
                    )
                    print(f"[agent] ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(new_sentences)} Ø¬Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {self.current_level}). Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {len(self.current_sentences)} Ø¬Ù…Ù„Ø©")
                    print(f"[agent] âœ¨ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {new_sentences}")
                else:
                    print(f"[agent] ØªÙ… ØªØ¬Ø§Ù‡Ù„ {len(found_sentences)} Ø¬Ù…Ù„Ø© Ù…ÙƒØ±Ø±Ø©: {found_sentences}")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¥Ø´Ø§Ø±Ø§Øª Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…Ù„Ø©
            completion_indicators = [
                "Ù…Ù…ØªØ§Ø²", "Ø£Ø­Ø³Ù†Øª", "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹", "excellent", "great", "perfect"
            ]
            
            if any(indicator in agent_text.lower() for indicator in completion_indicators):
                # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙÙƒØªÙ…Ù„Ø©
                self.sentences_completed = getattr(self, 'sentences_completed', 0) + 1
                # ØªØ­Ø¯ÙŠØ« current_sentence_index Ù„Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ³Ø§ÙˆÙŠ sentences_completed)
                self.current_sentence_index = self.sentences_completed
                
                print(f"[agent] Ø¬Ù…Ù„Ø© Ù…ÙƒØªÙ…Ù„Ø©! Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙƒØªÙ…Ù„: {self.sentences_completed}, Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ§Ù„ÙŠ: {self.current_sentence_index}")
                
                # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµØ­ÙŠØ­
                current_total = len(getattr(self, 'current_sentences', []))
                
                # Ø¥Ø°Ø§ Ø£ÙƒÙ…Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒÙ„ Ø¬Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø§Ù†ØªÙ‚Ù„ Ù„Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ
                sentences_per_level = 20  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ ÙƒÙ„ Ù…Ø³ØªÙˆÙ‰ (Ø­Ø³Ø¨ prompts.py)
                if (self.sentences_completed % sentences_per_level == 0 and 
                    self.sentences_completed > 0 and 
                    self.current_level < 5):
                    self.current_level += 1
                    print(f"[agent] ğŸ‰ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ù…Ø³ØªÙˆÙ‰ {self.current_level} - Ø£ÙƒÙ…Ù„Øª {self.sentences_completed} Ø¬Ù…Ù„Ø©!")
                
                await supabase_manager.update_sentences_progress(
                    self.user_id,
                    self.sentences_session_id,
                    completed_sentences=self.sentences_completed,
                    current_sentence_index=self.current_sentence_index,
                    generated_sentences=self.current_sentences,  # âœ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø©
                    total_sentences=current_total,
                    current_level=self.current_level,
                    learned_sentences_history=getattr(self, 'learned_sentences_history', [])
                )
                print(f"[agent] âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…: {self.sentences_completed}/{current_total} Ø¬Ù…Ù„Ø© Ù…ÙÙƒØªÙ…Ù„Ø© (Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {self.current_level})")
                
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø¯ Ø§Ù„Ø¬Ù…Ù„: {e}")

    async def load_podcast_progress(self):
        """ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ¯Ù…Ø¬Ù‡ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        if not self.user_id or self.mode != "english_conversation":
            return
            
        try:
            # Ø¬Ù„Ø¨ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¤Ù‡
            # ØªØ­Ù…ÙŠÙ„ ØµØ§Ù…Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.podcast_progress = await supabase_manager.get_or_create_podcast_progress(self.user_id)
            
            if self.podcast_progress:
                
                # Ø¯Ù…Ø¬ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙÙŠ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                if self.chat_ctx:
                    podcast_memory_context = self._build_podcast_memory_context()
                    if podcast_memory_context:
                        new_ctx = self.chat_ctx.copy()
                        new_ctx.add_message(role="system", content=podcast_memory_context)
                
        except Exception as e:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª
    
    def _build_podcast_memory_context(self) -> str:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª"""
        if not self.podcast_progress:
            return ""
        
        last_topic = self.podcast_progress.get('last_topic', '')
        last_position = self.podcast_progress.get('last_position', '')
        last_context = self.podcast_progress.get('last_context', '')
        conversation_summary = self.podcast_progress.get('conversation_summary', '')
        topics_discussed = self.podcast_progress.get('topics_discussed', [])
        total_conversations = self.podcast_progress.get('total_conversations', 0)
        fluency_level = self.podcast_progress.get('fluency_level', 'beginner')
        common_mistakes = self.podcast_progress.get('common_mistakes', [])
        improvements = self.podcast_progress.get('improvements', [])
        
        context = f"""
=== Podcast Conversation Memory for: {self.user_name} ===
ğŸ“Š Statistics:
- Total conversations: {total_conversations}
- Fluency level: {fluency_level}
- Topics discussed: {', '.join(topics_discussed[-5:]) if topics_discussed else 'None yet'}

ğŸ“ Last Session:
- Topic: {last_topic or 'First conversation'}
- Position: {last_position or 'Starting fresh'}
- Context: {last_context or 'No previous context'}
- Summary: {conversation_summary or 'This is our first conversation'}

ğŸ¯ Common Mistakes to Address:
{chr(10).join([f"- {mistake}" for mistake in common_mistakes[-5:]]) if common_mistakes else "- No mistakes recorded yet"}

âœ¨ Noticed Improvements:
{chr(10).join([f"- {improvement}" for improvement in improvements[-5:]]) if improvements else "- First session"}

ğŸ”¥ CRITICAL INSTRUCTIONS FOR RETURNING USER:
1. If there was a previous topic ({last_topic}), acknowledge it naturally:
   "Hey! Last time we were talking about {last_topic}. {last_position}"
   "Would you like to continue that conversation or talk about something new?"

2. Reference their progress naturally:
   - Mention improvements you've noticed
   - Gently correct recurring mistakes
   - Build on previous conversations

3. Adapt to their fluency level ({fluency_level}):
   - Beginner: Simple vocabulary, more support
   - Intermediate: Mix complexity, gentle corrections
   - Advanced: Natural flow, minimal interruptions

4. Make the conversation feel continuous and personal!
"""
        
        return context
    
    async def load_personal_context(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not self.user_id:
            return
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ
            self.personal_context = await supabase_manager.get_or_create_personal_context(self.user_id)
            
            if self.personal_context:
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ
                personal_memory = self._build_personal_context_memory()
                if personal_memory:
                    logging.info(f"[agent] âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ (Ø§ÙƒØªÙ…Ø§Ù„: {self.personal_context.get('context_completeness', 0)}%)")
        except Exception as e:
            logging.error(f"[agent] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ: {e}")
    
    async def load_gamification_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­ÙÙŠØ² ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª"""
        if not self.user_id:
            return
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª
            self.level_assessment = await supabase_manager.get_or_create_level_assessment(self.user_id)
            self.achievements = await supabase_manager.get_or_create_achievements(self.user_id)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ streak
            await supabase_manager.update_streak(self.user_id)
            
            # ØªØ³Ø¬ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­ÙÙŠØ²
            if self.achievements:
                logging.info(f"[agent] âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­ÙÙŠØ²:")
                logging.info(f"  - Level: {self.achievements.get('current_level', 1)}")
                logging.info(f"  - Points: {self.achievements.get('total_points', 0)}")
                logging.info(f"  - Streak: {self.achievements.get('current_streak', 0)} days")
                logging.info(f"  - Words: {self.achievements.get('total_words_learned', 0)}")
        except Exception as e:
            logging.error(f"[agent] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­ÙÙŠØ²: {e}")
    
    async def track_new_word(self, word: str, translation: str = "", example: str = "", topic: str = ""):
        """ØªØªØ¨Ø¹ ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©"""
        if not self.user_id or not word:
            return
        
        try:
            # Ø¥Ø¶Ø§ÙØ© Ù„Ù€ vocabulary_cards
            result = await supabase_manager.add_vocabulary_card(self.user_id, word, translation, example, topic)
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© (Ù„ÙŠØ³Øª Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹)
            if result.get("success") and not result.get("exists"):
                self.words_learned_session.append(word)
                
                # ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ user_achievements
                if self.achievements:
                    from supabase_client import supabase_manager as sm
                    client = sm.service_client if sm.service_client else sm.client
                    client.table("user_achievements").update({
                        "total_words_learned": self.achievements.get("total_words_learned", 0) + 1,
                        "updated_at": datetime.now().isoformat()
                    }).eq("user_id", self.user_id).execute()
                
                logging.info(f"[agent] ğŸ“š ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©: {word}")
        except Exception as e:
            logging.error(f"[agent] Ø®Ø·Ø£ ÙÙŠ ØªØªØ¨Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø©: {e}")
    
    async def award_points(self, points: int, reason: str = ""):
        """Ù…Ù†Ø­ Ù†Ù‚Ø§Ø· Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not self.user_id:
            return
        
        try:
            result = await supabase_manager.award_points(self.user_id, points, reason)
            
            if result.get("level_up"):
                # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø±ØªÙ‚Ù‰!
                new_level = result.get("new_level")
                celebration = f"ğŸ‰ LEVEL UP! You reached Level {new_level}! ğŸ‰"
                logging.info(f"[agent] ğŸ† LEVEL UP: {self.user_id} -> Level {new_level}")
                # ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‡Ù†Ø§
        except Exception as e:
            logging.error(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ù…Ù†Ø­ Ø§Ù„Ù†Ù‚Ø§Ø·: {e}")
    
    async def track_answer(self, correct: bool):
        """ØªØªØ¨Ø¹ Ø¥Ø¬Ø§Ø¨Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        self.session_total_attempts += 1
        if correct:
            self.session_correct_answers += 1
            # Ù…Ù†Ø­ Ù†Ù‚Ø§Ø·
            await self.award_points(5, "correct answer")
        
        # ğŸ“Š ØªØ­Ø¯ÙŠØ« daily_stats ÙÙˆØ±ÙŠØ§Ù‹ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù„Ø³Ø©
        if self.user_id:
            try:
                accuracy = (self.session_correct_answers / self.session_total_attempts * 100) if self.session_total_attempts > 0 else 0
                await supabase_manager.update_daily_stats(self.user_id, {
                    "correct_answers": self.session_correct_answers,
                    "total_attempts": self.session_total_attempts,
                    "daily_accuracy": accuracy
                })
            except Exception as e:
                pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª
    
    async def end_session_summary(self):
        """Ù…Ù„Ø®Øµ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù„Ø³Ø©"""
        if not self.user_id:
            return
        
        try:
            # Ø­Ø³Ø§Ø¨ Ù…Ø¯Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
            duration = (datetime.now() - self.session_start_time).seconds // 60
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            accuracy = 0
            if self.session_total_attempts > 0:
                accuracy = (self.session_correct_answers / self.session_total_attempts) * 100
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©
            await supabase_manager.update_daily_stats(self.user_id, {
                "minutes_studied": duration,
                "words_learned": len(self.words_learned_session),
                "correct_answers": self.session_correct_answers,
                "total_attempts": self.session_total_attempts
            })
            
            logging.info(f"[agent] ğŸ“Š Ø¬Ù„Ø³Ø© Ù…Ù†ØªÙ‡ÙŠØ©: {duration}Ø¯, {len(self.words_learned_session)} ÙƒÙ„Ù…Ø©, {accuracy:.1f}% Ø¯Ù‚Ø©")
        except Exception as e:
            logging.error(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")
    
    def _build_personal_context_memory(self) -> str:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø´Ø®ØµÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not self.personal_context:
            return ""
        
        context = f"""
=== ğŸŒŸ PERSONAL CONTEXT FOR: {self.user_name} ===

USE THIS INFORMATION TO CREATE PERSONALIZED, REAL-LIFE EXAMPLES!

ğŸ‘¤ **Basic Info:**
- Name: {self.personal_context.get('first_name', 'Unknown')}
- Age: {self.personal_context.get('age', 'Unknown')}
- Occupation: {self.personal_context.get('occupation', 'Unknown')}
- City: {self.personal_context.get('city', 'Unknown')}

ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Family & Friends:**
- Family members: {', '.join([f"{k}: {v}" for k, v in self.personal_context.get('family_members', {}).items()]) or 'Not yet collected'}
- Friends: {', '.join(self.personal_context.get('friends', [])) or 'Not yet collected'}
- Pets: {', '.join([f"{p.get('name')} ({p.get('type')})" for p in self.personal_context.get('pets', [])]) or 'None'}

â¤ï¸ **Interests & Preferences:**
- Hobbies: {', '.join(self.personal_context.get('hobbies', [])) or 'Not yet collected'}
- Favorite foods: {', '.join(self.personal_context.get('favorite_foods', [])) or 'Not yet collected'}
- Favorite colors: {', '.join(self.personal_context.get('favorite_colors', [])) or 'Not yet collected'}

ğŸ  **Environment:**
- Objects around: {', '.join(self.personal_context.get('objects_around', [])) or 'Not yet collected'}
- Home items: {', '.join(self.personal_context.get('home_items', [])) or 'Not yet collected'}
- Room: {self.personal_context.get('room_description', 'Not described yet')}

ğŸ¯ **Goals & Dreams:**
- Learning goals: {', '.join(self.personal_context.get('learning_goals', [])) or 'Not yet discussed'}
- Dream job: {self.personal_context.get('dream_job', 'Not shared yet')}
- Want to visit: {', '.join(self.personal_context.get('places_want_to_visit', [])) or 'Not shared yet'}

ğŸ“Š **Context Completeness: {self.personal_context.get('context_completeness', 0)}%**

âš ï¸ **CRITICAL INSTRUCTIONS:**

1. **IF INFO IS MISSING**: Ask naturally during the lesson!
   - Example: "Before we continue, what's your name?" (if name is missing)
   - Example: "Tell me, what objects do you see around you?" (when teaching nouns)

2. **USE THEIR ACTUAL INFO IN EXAMPLES**:
   - âŒ DON'T SAY: "John has a book"
   - âœ… DO SAY: "{self.personal_context.get('first_name', 'You')} has a {self.personal_context.get('objects_around', ['phone'])[0] if self.personal_context.get('objects_around') else 'phone'}"

3. **MAKE IT PERSONAL AND ENGAGING**:
   - Use their family names, friend names, hobbies, favorite things
   - Reference their daily life, environment, goals
   - Make them the HERO of every example!

4. **UPDATE AS YOU GO**:
   - When they mention new info, use it immediately
   - Keep the context fresh and current

**Remember**: This is THEIR English learning journey, not a generic textbook!
"""
        return context
    
    def _extract_personal_info_from_text(self, text: str) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø´Ø®ØµÙŠØ© Ù…Ù† Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not text:
            return {}
        
        text_lower = text.lower()
        updates = {}
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù…
        name_patterns = [
            r"(?:my name is|i'm|i am|call me|\u0627\u0633\u0645\u064a|\u0623\u0646\u0627)\s+([\u0627-\u064a\u0621-\u064a\w]+)",
            r"^([\u0627-\u064a\u0621-\u064a\w]+)$"  # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¥Ø¬Ø§Ø¨Ø© Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
        ]
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.UNICODE)
            if match and len(match.group(1)) > 1 and len(match.group(1)) < 20:
                potential_name = match.group(1).strip()
                # ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ØºÙŠØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
                excluded = ['yes', 'no', 'okay', 'sure', 'hello', 'hi', 'thanks', 'thank', 'Ù†Ø¹Ù…', 'Ù„Ø§', 'Ø´ÙˆÙƒØ±Ø§', 'Ù…Ø±Ø­Ø¨Ø§']
                if potential_name.lower() not in excluded:
                    updates['first_name'] = potential_name.title()
                    break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù…Ø±
        age_match = re.search(r'(?:\u0639\u0645\u0631\u064a|age|i am|i\'m|\u0623\u0646\u0627)\s*(\d{1,2})(?:\s*(?:year|\u0633\u0646\u0629|\u0639\u0627\u0645))?', text, re.IGNORECASE | re.UNICODE)
        if age_match:
            age = int(age_match.group(1))
            if 5 <= age <= 100:  # Ø¹Ù…Ø± Ù…Ù†Ø·Ù‚ÙŠ
                updates['age'] = age
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
        city_patterns = [
            r'(?:from|in|live in|\u0645\u0646|\u0641\u064a|\u0623\u0633\u0643\u0646 \u0641\u064a)\s+([\u0627-\u064a\u0621-\u064a\w\s]+?)(?:\.|,|$)',
            r'(?:city|\u0645\u062f\u064a\u0646\u0629|\u0645\u062f\u064a\u0646\u062a\u064a)\s+(?:is|:)?\s*([\u0627-\u064a\u0621-\u064a\w\s]+?)(?:\.|,|$)'
        ]
        for pattern in city_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.UNICODE)
            if match:
                city = match.group(1).strip()
                if len(city) > 2 and len(city) < 30:
                    updates['city'] = city.title()
                    break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù‡Ù†Ø©
        occupation_patterns = [
            r'(?:i\'m a|i am a|i work as|\u0623Ù†\u0627|\u0639Ù…Ù„\u064a)\s+(student|teacher|engineer|doctor|developer|designer|\u0637\u0627\u0644\u0628|\u0645Ù‡\u0646\u062f\u0633|\u0637\u0628\u064a\u0628|\u0645\u0639\u0644\u0645|\u0645\u0628\u0631\u0645\u062c)',
            r'(?:job|work|occupation|\u0645\u0647\u0646\u0629|\u0639\u0645\u0644)\s*(?:is|:)?\s*([\u0627-\u064a\u0621-\u064a\w]+)'
        ]
        for pattern in occupation_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.UNICODE)
            if match:
                updates['occupation'] = match.group(1).strip()
                break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‡ÙˆØ§ÙŠØ§Øª
        hobby_keywords = ['football', 'soccer', 'reading', 'cooking', 'gaming', 'music', 'swimming', 'running',
                         'Ù‚Ø±Ø§Ø¡Ø©', 'ÙƒØ±Ø©', 'Ø·Ø¨Ø®', 'Ø£Ù„Ø¹Ø§Ø¨', 'Ù…ÙˆØ³ÙŠÙ‚Ù‰', 'Ø³Ø¨Ø§Ø­Ø©', 'Ø¬Ø±ÙŠ']
        found_hobbies = []
        for hobby in hobby_keywords:
            if hobby in text_lower:
                found_hobbies.append(hobby)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙˆØ§Ø¦Ù… Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…
        list_match = re.findall(r'([\u0627-\u064a\u0621-\u064a\w]+)\s*(?:,|\u0648)\s*([\u0627-\u064a\u0621-\u064a\w]+)', text, re.UNICODE)
        if list_match and not updates.get('first_name'):  # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ø£ Ø§Ø³Ù…
            items = [item for pair in list_match for item in pair]
            # Ù‚Ø¯ ØªÙƒÙˆÙ† Ø£Ø³Ù…Ø§Ø¡ Ø£Ø´ÙŠØ§Ø¡ Ù…Ø­ÙŠØ·Ø©
            if any(word in text_lower for word in ['see', 'have', 'around', 'Ø­ÙˆÙ„', 'Ø¹Ù†Ø¯ÙŠ', 'Ø£Ø±Ù‰']):
                found_hobbies.extend(items[:3])  # Ø£ÙˆÙ„ 3 Ø¹Ù†Ø§ØµØ±
        
        if found_hobbies:
            updates['hobbies'] = found_hobbies[:5]  # Ø£Ù‚ØµÙ‰ 5
        
        return updates
    
    async def update_personal_context_from_conversation(self, detected_info: dict):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        if not self.user_id or not detected_info:
            return
        
        try:
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            await supabase_manager.update_personal_context(self.user_id, detected_info)
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            if self.personal_context:
                self.personal_context.update(detected_info)
                print(f"[agent] âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ: {list(detected_info.keys())}")
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³ÙŠØ§Ù‚: {e}")
    
    async def _auto_extract_and_save_context(self, user_message: str):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        if not user_message or not self.user_id:
            return
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            extracted = self._extract_personal_info_from_text(user_message)
            
            if extracted:
                # Ø­ÙØ¸ ÙÙˆØ±Ø§Ù‹
                await self.update_personal_context_from_conversation(extracted)
        except Exception as e:
            # Ø®Ø·Ø£ ØµØ§Ù…Øª - Ù„Ø§ Ù†Ø±ÙŠØ¯ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            pass
    
    async def load_user_memory(self):
        """ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not self.user_id:
            return
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø´Ø®ØµÙŠ Ø£ÙˆÙ„Ø§Ù‹ (Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ¶Ø§Ø¹)
        await self.load_personal_context()
        
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­ÙÙŠØ² (Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ¶Ø§Ø¹)
        await self.load_gamification_data()
            
        # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠ ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ØŒ Ø­Ù…Ù„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„ ÙÙ‚Ø·
        if self.mode == "sentences_learning":
            await self.load_sentences_progress()
            return  # Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­Ù…ÙŠÙ„ user_progress ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³ØªØŒ Ø­Ù…Ù„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª
        if self.mode == "english_conversation":
            await self.load_podcast_progress()
            return
        
        try:
            # ØªØ­Ù…ÙŠÙ„ ØµØ§Ù…Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† Ø·Ø¨Ø§Ø¹Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            self.user_progress = await supabase_manager.get_or_create_user_progress(self.user_id)
            
            # ØªØ­Ø¯ÙŠØ« Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
            if self.user_progress:
                memory_context = self._build_memory_context()
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØªØ­Ø¯ÙŠØ«Ù‡Ø§
                new_ctx = self.chat_ctx.copy()
                new_ctx.add_message(role="system", content=memory_context)
                await self.update_chat_ctx(new_ctx)
                
        except Exception as e:
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            pass
    
    def _build_memory_context(self) -> str:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© - ÙŠØ¯Ø¹Ù… Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙˆÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„"""
        
        # ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ - Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ù…Ø®ØªÙ„Ù
        if self.mode == "sentences_learning":
            return self._build_sentences_memory_context()
        
        # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
        if not self.user_progress:
            return ""
        
        # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©
        vocabulary = self.user_progress.get('vocabulary', {})
        learned_words = list(vocabulary.keys())[:10]  # Ø£ÙˆÙ„ 10 ÙƒÙ„Ù…Ø§Øª
        
        # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ
        current_topic = self.user_progress.get('current_topic', '')
        progress_percentage = self.user_progress.get('progress_percentage', 0)
        is_topic_incomplete = current_topic and progress_percentage < 100
        
        context = f"""
=== Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {self.user_name} ===
ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…:
- Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©: {self.user_progress.get('words_learned', 0)}
- Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù…: {progress_percentage}%
- Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©: {self.user_progress.get('last_session_at', 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ù„Ø³Ø§Øª Ø³Ø§Ø¨Ù‚Ø©')}

ğŸ“š Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_topic or 'Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø¨Ø¹Ø¯'}
ğŸ“ Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© ØªÙˆÙ‚Ù: {self.user_progress.get('last_position', 'Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©')}
âœ… Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©: {', '.join(self.user_progress.get('topics_completed', [])) or 'Ù„Ø§ ØªÙˆØ¬Ø¯'}

ğŸ”¤ Ø¨Ø¹Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©: {', '.join(learned_words) if learned_words else 'Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ø¨Ø¹Ø¯'}

ğŸ¯ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯:
{"âš ï¸ Ù‡Ù†Ø§Ùƒ Ù…ÙˆØ¶ÙˆØ¹ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„!" if is_topic_incomplete else "âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹Ù„Ù‚"}

CRITICAL INSTRUCTIONS FOR RETURNING USER:
1. Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…ÙˆØ¶ÙˆØ¹ Ø­Ø§Ù„ÙŠ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„ ({current_topic}), ÙŠØ¬Ø¨ Ø£Ù† ØªØ³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
   "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰! Ø£Ø±Ù‰ Ø£Ù†Ùƒ ÙƒÙ†Øª ØªØ¯Ø±Ø³ Ù…ÙˆØ¶ÙˆØ¹ {current_topic} ÙˆØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ {self.user_progress.get('last_position', 'Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©')}"
   "Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ù†ÙƒÙ…Ù„ Ù…Ù† Ø­ÙŠØ« ØªÙˆÙ‚ÙÙ†Ø§ØŒ Ø£Ù… ØªÙØ¶Ù„ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ØŸ"

2. Ø§Ù†ØªØ¸Ø± Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‚Ø¨Ù„ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© - Ù„Ø§ ØªÙØªØ±Ø¶ Ø£ÙŠ Ø´ÙŠØ¡!

3. Ø¥Ø°Ø§ Ø§Ø®ØªØ§Ø± "Ù†ÙƒÙ…Ù„":
   - Ø§Ø³ØªÙƒÙ…Ù„ Ù…Ù† Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© ØªÙˆÙ‚Ù
   - Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø³Ø±Ø¹Ø©
   - ØªØ§Ø¨Ø¹ Ø§Ù„Ø´Ø±Ø­ Ù…Ù† Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©

4. Ø¥Ø°Ø§ Ø§Ø®ØªØ§Ø± "Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯":
   - Ø§Ù‚ØªØ±Ø­ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
   - Ø§Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
   - Ø§Ø¨Ø¯Ø£ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø³Ø±ÙŠØ¹ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±

5. Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯: Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø¹ØªØ§Ø¯ (5 Ø£Ø³Ø¦Ù„Ø©) Ø«Ù… Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡

6. Ø§Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©
"""
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±
        conversation_history = self.user_progress.get('conversation_history', {})
        if conversation_history:
            recent_sessions = list(conversation_history.items())[-2:]  # Ø¢Ø®Ø± Ø¬Ù„Ø³ØªÙŠÙ†
            context += "\nğŸ“ Ø¢Ø®Ø± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª:\n"
            for session_id, session_data in recent_sessions:
                topic = session_data.get('topic', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                words_count = len(session_data.get('words_discussed', []))
                last_pos = session_data.get('last_position', '')
                context += f"- {topic}: {words_count} ÙƒÙ„Ù…Ø©ØŒ ØªÙˆÙ‚Ù Ø¹Ù†Ø¯: {last_pos}\n"
        
        context += "\nâš ï¸ Ù…Ù‡Ù…: Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ØªÙ‚Ø¯ÙŠÙ… ØªØ¬Ø±Ø¨Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ØªÙˆØ§ØµÙ„Ø© ÙˆÙ…Ø®ØµØµØ©!\n"
        
        return context
    
    def _build_sentences_memory_context(self) -> str:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„"""
        if not self.sentences_progress:
            return ""
        
        # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©
        learned_sentences_history = self.sentences_progress.get('learned_sentences_history', [])
        current_sentences = self.sentences_progress.get('generated_sentences', [])
        completed_sentences = self.sentences_progress.get('completed_sentences', 0)
        current_level = self.sentences_progress.get('current_level', 1)
        current_sentence_index = self.sentences_progress.get('current_sentence_index', 0)
        total_sentences = len(current_sentences)
        
        # Ø¢Ø®Ø± 10 Ø¬Ù…Ù„ Ù…ØªØ¹Ù„Ù…Ø©
        recent_learned = learned_sentences_history[-10:] if learned_sentences_history else []
        
        # Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        remaining_sentences = current_sentences[current_sentence_index:current_sentence_index + 5] if current_sentences else []
        
        context = f"""
=== Ø°Ø§ÙƒØ±Ø© ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…: {self.user_name} ===
ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©:
- Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_level}
- Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©: {completed_sentences}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©: {total_sentences}
- Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: {current_sentence_index + 1}

ğŸ“ Ø¢Ø®Ø± 10 Ø¬Ù…Ù„ ØªØ¹Ù„Ù…Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{chr(10).join([f"- {sentence}" for sentence in recent_learned]) if recent_learned else "- Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ù…Ù„ Ù…ØªØ¹Ù„Ù…Ø© Ø¨Ø¹Ø¯"}

ğŸ¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©:
{chr(10).join([f"- {sentence}" for sentence in remaining_sentences]) if remaining_sentences else "- Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©"}

ğŸ”¥ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„:
1. Ø£Ù†Øª ÙÙŠ ÙˆØ¶Ø¹ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© - Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù…Ù„ ÙÙ‚Ø·
2. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªØ¹Ù„Ù… Ø¨Ø§Ù„ÙØ¹Ù„ {len(learned_sentences_history)} Ø¬Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹
3. ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ°ÙƒØ± Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ØªÙŠ ØªØ¹Ù„Ù…Ù‡Ø§ ÙˆØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø±Ù‡Ø§
4. Ø§Ø¨Ø¯Ø£ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {current_level} ÙˆØ§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØªØ¯Ø±Ø¬
5. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø© ÙƒÙ…Ø±Ø¬Ø¹ Ù„Ø¨Ù†Ø§Ø¡ Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©
6. Ø§Ù†ØªØ¨Ù‡ Ù„Ù„ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ Ù…Ù† Ø§Ù„Ø¨Ø³ÙŠØ· Ù„Ù„Ù…Ø¹Ù‚Ø¯

âš ï¸ CRITICAL: ØªØ°ÙƒØ± Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø£Ø¹Ù„Ø§Ù‡ - Ù„Ø§ ØªÙƒØ±Ø±Ù‡Ø§!
"""
        
        return context
    
    async def save_session_progress(self, topic: str = "", words_discussed: list = None, progress_made: int = 0, last_position: str = "", session_summary: str = ""):
        """Ø­ÙØ¸ ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© - Ù…Ù†ÙØµÙ„ Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙˆÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ ÙˆÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª"""
        if not self.user_id:
            return
            
        # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù„Ø§ Ù†Ø­ÙØ¸ ÙÙŠ user_progress - Ù†Ø¸Ø§Ù… Ù…Ù†ÙØµÙ„
        if self.mode == "sentences_learning":
            print(f"[agent] ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ - ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø­ÙØ¸ user_progress")
            return
        
        # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³ØªØŒ Ù†Ø­ÙØ¸ ÙÙŠ podcast_progress
        if self.mode == "english_conversation":
            await self.save_podcast_progress(topic, words_discussed, last_position, session_summary)
            return
        
        try:
            # ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            if topic:
                self.session_data["current_topic"] = topic
            if words_discussed:
                self.session_data["words_discussed"] = words_discussed
            if last_position:
                self.session_data["last_position"] = last_position
            
            conversation_data = {
                "session_id": self.session_data["session_id"],
                "topic": topic or self.session_data.get("current_topic", ""),
                "words_discussed": words_discussed or self.session_data.get("words_discussed", []),
                "progress_made": progress_made,
                "last_position": last_position or self.session_data.get("last_position", ""),
                "session_summary": session_summary,
                "session_data": self.session_data
            }
            
            # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ø§Ù„Ù…Ø¹Ø²ÙˆÙ„)
            if self.mode != "english_conversation":
                await supabase_manager.save_conversation_data(self.user_id, conversation_data)
            
            # ØªØ­Ø¯ÙŠØ« Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù… ÙˆØ§Ù„Ù…ÙˆØ¶Ø¹ ÙÙ‚Ø· (Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙÙ‚Ø·)
            current_words_count = len(set(self.session_data.get("words_discussed", [])))
            current_topic = self.session_data.get("current_topic", "")
            last_position = self.session_data.get("last_position", "")
            
            # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø­ÙØ¸
            if current_words_count > 0 or current_topic or last_position:
                await supabase_manager.update_user_progress(
                    user_id=self.user_id,
                    current_topic=current_topic or "General",  # Ù…ÙˆØ¶ÙˆØ¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                    last_position=last_position or "In progress",  # Ù…ÙˆØ¶Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                    progress_percentage=min(100, current_words_count * 2)  # ÙƒÙ„ ÙƒÙ„Ù…Ø© = 2%
                )
                # Ø±Ø³Ø§Ù„Ø© ØªØ´Ø®ÙŠØµÙŠØ©
                print(f"[SAVE] âœ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù…: Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹={current_topic or 'N/A'}, Ø§Ù„Ù…ÙˆØ¶Ø¹={last_position or 'N/A'}, Ø§Ù„ÙƒÙ„Ù…Ø§Øª={current_words_count}")
            
        except Exception as e:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    
    async def save_podcast_progress(self, topic: str = "", words_discussed: list = None, last_position: str = "", session_summary: str = ""):
        """Ø­ÙØ¸ ØªÙ‚Ø¯Ù… Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ÙØµÙ„Ø©"""
        if not self.user_id or self.mode != "english_conversation":
            return
        
        try:
            # Ø­Ø³Ø§Ø¨ Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            duration_minutes = 0
            if hasattr(self, 'conversation_start_time'):
                duration_minutes = int((datetime.now() - self.conversation_start_time).total_seconds() / 60)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ­Ø¯Ø¯
            if not topic:
                topic = self.session_data.get("current_topic", "")
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…ÙˆØ¶ÙˆØ¹ØŒ Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª
            if not topic and hasattr(self, 'session_data'):
                words = self.session_data.get("words_discussed", [])
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
                topic_keywords = {
                    'technology': ['technology', 'computer', 'phone', 'internet', 'software', 'hardware'],
                    'travel': ['travel', 'trip', 'vacation', 'flight', 'hotel', 'tourism'],
                    'food': ['food', 'eat', 'meal', 'restaurant', 'cook', 'recipe'],
                    'sports': ['sport', 'football', 'basketball', 'tennis', 'gym', 'exercise'],
                    'work': ['work', 'job', 'office', 'career', 'business', 'company']
                }
                
                for topic_name, keywords in topic_keywords.items():
                    if any(word in words for word in keywords):
                        topic = topic_name.capitalize()
                        self.session_data["current_topic"] = topic
                        break
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
            vocabulary = words_discussed or self.conversation_vocabulary or []
            
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ù„Ø§Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡
            fluency_level = self.podcast_progress.get('fluency_level', 'beginner') if self.podcast_progress else 'beginner'
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ù…ÙˆÙ‚Ù Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            if topic:
                context = f"Discussing {topic}"
                if not last_position:
                    last_position = f"In the middle of talking about {topic}"
            else:
                context = "General conversation"
                last_position = "General English practice"
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ù„Ø­ÙØ¸
            conversation_data = {
                "topic": topic,
                "context": context,
                "position": last_position,
                "summary": session_summary or f"Discussed {topic or 'various topics'} for {duration_minutes} minutes",
                "duration_minutes": duration_minutes,
                "vocabulary": vocabulary,
                "mistakes": self.conversation_mistakes if hasattr(self, 'conversation_mistakes') else [],
                "improvements": self.conversation_improvements if hasattr(self, 'conversation_improvements') else [],
                "fluency_level": fluency_level
            }
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            result = await supabase_manager.save_podcast_conversation(self.user_id, conversation_data)
            
            # Ø±Ø³Ø§Ù„Ø© ØªØ´Ø®ÙŠØµÙŠØ©
            if result.get("success"):
                print(f"[agent] âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª: Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹={topic}, Ø§Ù„Ù…ÙˆÙ‚Ù={last_position}")
            else:
                print(f"[agent] âš ï¸ ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸: {result.get('error', 'Unknown')}")
            
        except Exception as e:
            print(f"[agent] âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª: {e}")
            import traceback
            traceback.print_exc()
    
    def update_session_data(self, topic: str = None, words: list = None, position: str = None):
        """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        if topic:
            self.session_data["current_topic"] = topic
        if words:
            self.session_data["words_discussed"].extend(words)
        if position:
            self.session_data["last_position"] = position
    
    async def auto_save_progress(self):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙƒÙ„ ÙØªØ±Ø© - Ù…Ù†ÙØµÙ„ Ù„Ù„Ø£ÙˆØ¶Ø§Ø¹ Ø§Ù„Ø«Ù„Ø§Ø«Ø©"""
        # ØªØ£Ø¬ÙŠÙ„ Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ø£ÙˆÙ„ 30 Ø«Ø§Ù†ÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        if not hasattr(self, '_session_start_time'):
            self._session_start_time = datetime.now()
        
        elapsed = (datetime.now() - self._session_start_time).total_seconds()
        if elapsed < 30:
            return  # Ù„Ø§ ØªØ­ÙØ¸ ÙÙŠ Ø£ÙˆÙ„ 30 Ø«Ø§Ù†ÙŠØ©
        
        # debouncing: ØªØ¬Ù†Ø¨ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù…ØªÙƒØ±Ø± (ÙƒÙ„ 10 Ø«ÙˆØ§Ù†Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)
        if hasattr(self, '_last_auto_save'):
            time_since_last_save = (datetime.now() - self._last_auto_save).total_seconds()
            if time_since_last_save < 10:
                return
        
        # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ù†Ø¸Ø§Ù… Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø®ØµØµ
        if self.mode == "sentences_learning":
            return  # Ø§Ù„Ø­ÙØ¸ ÙŠØªÙ… Ø¹Ø¨Ø± process_sentences_response
        
        # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³ØªØŒ Ù†Ø­ÙØ¸ ÙÙŠ podcast_progress
        if self.mode == "english_conversation":
            if self.session_data.get("current_topic") or self.session_data.get("words_discussed"):
                await self.save_podcast_progress(
                    topic=self.session_data.get("current_topic", "General conversation"),
                    words_discussed=self.session_data.get("words_discussed", []),
                    last_position=self.session_data.get("last_position", "In conversation"),
                    session_summary="Auto-save during conversation"
                )
                self._last_auto_save = datetime.now()
            return
            
        # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙÙ‚Ø·
        if self.session_data.get("current_topic") or self.session_data.get("words_discussed"):
            await self.save_session_progress(
                topic=self.session_data.get("current_topic", ""),
                words_discussed=self.session_data.get("words_discussed", []),
                last_position=self.session_data.get("last_position", ""),
                session_summary="Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ"
            )
            self._last_auto_save = datetime.now()
    
    async def _on_user_input_transcribed(self, event):
        """Ù…Ø¹Ø§Ù„Ø¬ Ù†Ø³Ø® ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Ø³Ø® Ù†Ù‡Ø§Ø¦ÙŠ
            if not event.is_final:
                return
                
            user_text = event.transcript
            # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
            
            # ğŸ’¾ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© Ù…Ù† ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            await self._auto_extract_and_save_context(user_text)
            
            # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù†Ø¹Ø§Ù„Ø¬ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if self.mode == "sentences_learning":
                await self.process_user_sentence_attempt(user_text)
            
            # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³ØªØŒ Ù†Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙŠØ¶Ø§Ù‹
            if self.mode == "english_conversation":
                common_topics = ['technology', 'phones', 'computers', 'travel', 'food', 'sports', 
                               'movies', 'music', 'work', 'study', 'hobbies', 'family', 'weather']
                
                for topic in common_topics:
                    if topic in user_text.lower():
                        if not self.session_data.get("current_topic"):
                            self.session_data["current_topic"] = topic.capitalize()
                            print(f"[DEBUG] Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {topic.capitalize()}")
                            # Ø­ÙØ¸ ÙÙˆØ±ÙŠ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹
                            await self.save_podcast_progress(
                                topic=topic.capitalize(),
                                last_position=f"User mentioned {topic}"
                            )
                        break
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if any(keyword in user_text.lower() for keyword in ['Ù…ØªØ§Ø¨Ø¹Ø©', 'Ø§Ø³ØªØ¦Ù†Ø§Ù', 'Ù…Ù† Ø­ÙŠØ« ØªÙˆÙ‚ÙØª']):
                # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
                await self.continue_previous_topic()
                # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ§Ø± Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
            elif any(keyword in user_text.lower() for keyword in ['Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯', 'Ø¨Ø¯Ø¡ Ø¬Ø¯ÙŠØ¯', 'Ø´ÙŠØ¡ Ø¬Ø¯ÙŠØ¯', 'Ù…ÙˆØ¶ÙˆØ¹ Ø¢Ø®Ø±']):
                # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ø¨Ø¯Ø¡ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ù†Øµ
                new_topic_match = re.search(r'(?:Ù…ÙˆØ¶ÙˆØ¹|\btØ¹Ù„Ù…|\bØ¯Ø±Ø³)\s*(?:Ø¬Ø¯ÙŠØ¯|\bØ¹Ù†)?\s*[:ØŸ]?\s*(.+)', user_text)
                if new_topic_match:
                    new_topic = new_topic_match.group(1).strip().rstrip('.,!?ØŸØŒ')
                    if new_topic and len(new_topic) > 2:
                        await self.start_new_topic(new_topic)
                        # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ§Ø± Ù…ÙˆØ¶ÙˆØ¹Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹
                else:
                    # Ø¥Ø°Ø§ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŒ Ù†Ø¨Ø¯Ø£ Ø¨Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©
                    await self.start_new_topic("Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯")
                    # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø®ØªØ§Ø± Ø¨Ø¯Ø¡ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯
            elif any(keyword in user_text.lower() for keyword in ['Ù…ÙˆØ¶ÙˆØ¹', 'Ø¯Ø±Ø³', 'ØªØ¹Ù„Ù…', 'ÙƒÙ„Ù…Ø©']):
                # Ø­ÙØ¸ Ø¹Ø§Ø¯ÙŠ Ù„Ù„ØªÙ‚Ø¯Ù…
                await self.auto_save_progress()
                
        except Exception as e:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª
    
    async def _on_conversation_item_added(self, event):
        """Ù…Ø¹Ø§Ù„Ø¬ Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            item = event.item
            agent_text = ""  # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
            if item.role == "assistant":
                agent_text = item.text_content or ""
                # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
                
                # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù†Ø­ØªØ§Ø¬ Ù„Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙÙˆÙ„Ø¯Ø© ÙˆØ§Ù„ØªÙ‚Ø¯Ù…
                if self.mode == "sentences_learning":
                    await self.process_sentences_response(agent_text)
                
                # ğŸ¯ ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©/Ø§Ù„Ø®Ø§Ø·Ø¦Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
                correct_indicators = ['excellent', 'great', 'perfect', 'correct', 'right', 'well done',
                                     'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'ØµØ­ÙŠØ­', 'Ø£Ø­Ø³Ù†Øª', 'Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹']
                wrong_indicators = ['incorrect', 'wrong', 'not quite', 'try again', 'mistake',
                                   'Ø®Ø·Ø£', 'ØºÙŠØ± ØµØ­ÙŠØ­', 'Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰']
                
                agent_lower = agent_text.lower()
                if any(indicator in agent_lower for indicator in correct_indicators):
                    await self.track_answer(correct=True)
                elif any(indicator in agent_lower for indicator in wrong_indicators):
                    await self.track_answer(correct=False)
                
                # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³ØªØŒ Ù†Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                if self.mode == "english_conversation":
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©
                    common_topics = ['technology', 'phones', 'computers', 'travel', 'food', 'sports', 
                                   'movies', 'music', 'work', 'study', 'hobbies', 'family', 'weather']
                    
                    for topic in common_topics:
                        if topic in agent_text.lower():
                            if not self.session_data.get("current_topic"):
                                self.session_data["current_topic"] = topic.capitalize()
                                print(f"[DEBUG] Ø§Ø³ØªØ®Ø±Ø¬Øª Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {topic.capitalize()}")
                            break
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ø±Ø¯
                english_words = re.findall(r'\b[A-Za-z]{3,}\b', agent_text)
                if english_words:
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù‚Ø§Ø¦Ù…Ø©
                    current_words = self.session_data.get("words_discussed", [])
                    new_words = [word.lower() for word in english_words if word.lower() not in current_words]
                    if new_words:
                        current_words.extend(new_words)
                        self.session_data["words_discussed"] = current_words
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ù…Ø­Ø³Ù‘Ù†Ø©
                topic_patterns = [
                    # English patterns - Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø¨Ø§Ø´Ø±Ø©
                    r"\b(Nouns|Verbs|Adjectives|Adverbs|Pronouns|Prepositions|Conjunctions|Articles|Tenses|Grammar)\b",
                    r"(?:topic|subject)\s+(?:is|are|will be)\s+([A-Z][A-Za-z\s]+)",
                    r"(?:studying|learning|teaching|discussing)\s+([A-Z][A-Za-z\s]+)",
                    r"(?:Let's|let's)\s+(?:learn|study|talk about|discuss)\s+([A-Z][A-Za-z\s]+)",
                    r"(?:Today's topic|Our topic|The topic)\s+(?:is|will be)?:?\s*([A-Z][A-Za-z\s]+)",
                    r"(?:chapter|lesson|section)\s+(?:on|about)\s+([A-Z][A-Za-z\s]+)",
                    # Arabic patterns
                    r'Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹\s+(?:Ø§Ù„Ø­Ø§Ù„ÙŠ|Ø§Ù„ÙŠÙˆÙ…)[:ØŸ]?\s*(.+)',
                    r'Ø³Ù†ØªØ¹Ù„Ù…\s+(?:Ø¹Ù†|Ù…ÙˆØ¶ÙˆØ¹)\s*(.+)',
                    r'Ø¯Ø¹Ù†Ø§\s+Ù†ØªØ­Ø¯Ø«\s+Ø¹Ù†\s*(.+)',
                    r'Ù…ÙˆØ¶ÙˆØ¹\s+Ø§Ù„Ø£Ø³Ù…Ø§Ø¡'  # "Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡" -> Nouns
                ]
                
                for pattern in topic_patterns:
                    matches = re.findall(pattern, agent_text, re.IGNORECASE)
                    if matches:
                        new_topic = matches[0].strip().rstrip('.,!?ØŸØŒ')
                        if new_topic and len(new_topic) > 3 and new_topic != self.session_data.get("current_topic"):
                            self.session_data["current_topic"] = new_topic
                            # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
                            break
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙˆÙ‚Ù Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ù…Ø­Ø³Ù‘Ù†Ø©
            if agent_text:
                position_patterns = [
                    # English patterns - Ù…ÙˆØ§Ø¶Ø¹ Ù…Ø­Ø¯Ø¯Ø©
                    r"\b(types of nouns|common nouns|proper nouns|abstract nouns|collective nouns|countable nouns|uncountable nouns)\b",
                    r"\b(present tense|past tense|future tense|verb forms|irregular verbs)\b",
                    r"\b(definition|examples|usage|rules|exceptions)\b",
                    r"(?:We were|You were)\s+(?:discussing|talking about|learning)\s+([A-Za-z][A-Za-z\s]+)",
                    r"(?:Last time|Previously|Earlier).*?(?:about|discussing|studying)\s+([A-Za-z][A-Za-z\s]+)",
                    r"(?:stopped at|paused at|left off at|ended with)\s+([A-Za-z][A-Za-z\s]+)",
                    r"(?:covered|finished|completed)\s+([A-Za-z][A-Za-z\s]+)",
                    # Arabic patterns  
                    r'Ù†Ù‚Ø·Ø©\s+Ø§Ù„ØªÙˆÙ‚Ù[:ØŸ]?\s*(.+)',
                    r'ÙˆØµÙ„Ù†Ø§\s+Ø¥Ù„Ù‰\s*(.+)',
                    r'Ø§Ù†ØªÙ‡ÙŠÙ†Ø§\s+Ù…Ù†\s*(.+)',
                    r'ØªØ¹Ù„Ù…Ù†Ø§\s+Ø¹Ù†\s*(.+)'
                ]
                
                for pattern in position_patterns:
                    matches = re.findall(pattern, agent_text, re.IGNORECASE)
                    if matches:
                        new_position = matches[0].strip().rstrip('.,!?ØŸØŒ')
                        if new_position and len(new_position) > 3:
                            self.session_data["last_position"] = new_position
                            # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
                            break
                    
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… ÙƒÙ„ 3 Ø±Ø³Ø§Ø¦Ù„ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
            self._message_count += 1
            if self._message_count % 3 == 0:
                await self.auto_save_progress()
                
        except Exception as e:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª
    
    async def force_save_progress(self, topic: str = None, words: list = None, position: str = None):
        """Ø­ÙØ¸ ÙÙˆØ±ÙŠ Ù„Ù„ØªÙ‚Ø¯Ù… - Ù…Ù†ÙØµÙ„ Ù„Ù„ÙˆØ¶Ø¹ÙŠÙ†"""
        try:
            # ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ÙÙˆØ±ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…
            if self.mode == "sentences_learning":
                # ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ù…Ù„ - ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ÙÙˆØ±ÙŠ
                return
                
            if topic:
                self.session_data["current_topic"] = topic
            if words:
                self.session_data["words_discussed"] = words
            if position:
                self.session_data["last_position"] = position
            
            # Ø­ÙØ¸ ÙÙˆØ±ÙŠ ØµØ§Ù…Øª
            
            await self.save_session_progress(
                topic=self.session_data.get("current_topic", ""),
                words_discussed=self.session_data.get("words_discussed", []),
                last_position=self.session_data.get("last_position", ""),
                session_summary=f"Ø­ÙØ¸ ÙÙˆØ±ÙŠ - {len(self.session_data.get('words_discussed', []))} ÙƒÙ„Ù…Ø©"
            )
            
        except Exception as e:
            pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    
    async def continue_previous_topic(self):
        """Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù…Ù† Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© ØªÙˆÙ‚Ù"""
        if not self.user_progress:
            return
        
        try:
            # ØªØ·Ø¨ÙŠÙ‚ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
            if self.user_progress.get('current_topic'):
                self.session_data["current_topic"] = self.user_progress.get('current_topic')
            if self.user_progress.get('last_position'):
                self.session_data["last_position"] = self.user_progress.get('last_position')
            if self.user_progress.get('vocabulary'):
                # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹
                learned_words = list(self.user_progress.get('vocabulary', {}).keys())
                self.session_data["words_discussed"] = learned_words
            
            print(f"[agent] ØªÙ… Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚: {self.session_data.get('current_topic')} Ù…Ù† {self.session_data.get('last_position')}")
            
            # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙˆØ§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ„ 3 Ø±Ø³Ø§Ø¦Ù„
            self._message_count += 1
            if self._message_count % 3 == 0:
                await self.auto_save_progress()
                print(f"[agent] Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ {self._message_count} Ø±Ø³Ø§Ø¦Ù„")
                
            # Ø§Ù„Ø­ÙØ¸ Ø§Ù„ÙÙˆØ±ÙŠ Ø¥Ø°Ø§ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù…ÙˆØ¶ÙˆØ¹ Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
            if (self.session_data.get("current_topic") and 
                self.session_data.get("words_discussed")):
                await self.force_save_progress(
                    topic=self.session_data.get("current_topic"),
                    words=self.session_data.get("words_discussed"),
                    position=self.session_data.get("last_position", "")
                )
            
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚: {e}")
    
    async def start_new_topic(self, new_topic: str):
        """Ø¨Ø¯Ø¡ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ ÙˆÙ…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³Ø­ (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªÙ‚Ø¯Ù…)
            if self.session_data.get("current_topic") or self.session_data.get("words_discussed"):
                await self.save_session_progress(
                    topic=self.session_data.get("current_topic", ""),
                    words_discussed=self.session_data.get("words_discussed", []),
                    last_position=self.session_data.get("last_position", ""),
                    session_summary=f"Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚ - {len(self.session_data.get('words_discussed', []))} ÙƒÙ„Ù…Ø©"
                )
            
            # Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© ÙˆØ¨Ø¯Ø¡ Ø¬Ø¯ÙŠØ¯
            self.session_data = {
                "session_id": str(datetime.now().timestamp()),
                "start_time": datetime.now().isoformat(),
                "words_discussed": [],
                "topics_covered": [],
                "current_topic": new_topic,
                "last_position": "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹"
            }
            
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            self._message_count = 0
            
            print(f"[agent] ØªÙ… Ø¨Ø¯Ø¡ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯: {new_topic}")
            
        except Exception as e:
            print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {e}")


async def entrypoint(ctx: agents.JobContext):
    print("[agent] entrypoint: starting")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† job metadata
    user_name = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    full_name = ""
    user_id = None
    mode = "normal"  # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    voice_name = "Aoede"  # ğŸ¤ Ø§Ù„ØµÙˆØª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© metadata Ù…Ù† job Ø£ÙˆÙ„Ø§Ù‹
        if ctx.job.metadata:
            print(f"[agent] job metadata Ù…ÙˆØ¬ÙˆØ¯: {ctx.job.metadata}")
            metadata = json.loads(ctx.job.metadata)
            user_name = metadata.get("username", "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
            full_name = metadata.get("full_name", user_name)
            user_id = metadata.get("user_id")
            mode = metadata.get("mode", "normal")
            voice_name = metadata.get("voice_name", "Aoede")  # ğŸ¤ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª
            print(f"[agent] Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† job: Ø§Ù„Ø§Ø³Ù…={user_name}, Ø§Ù„Ù…Ø¹Ø±Ù={user_id}, Ø§Ù„ÙˆØ¶Ø¹={mode}, Ø§Ù„ØµÙˆØª={voice_name}")
        else:
            print("[agent] Ù„Ø§ ÙŠÙˆØ¬Ø¯ job metadataØŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© room metadata...")
    except (json.JSONDecodeError, TypeError) as e:
        print(f"[agent] ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© job metadata: {e}")
    
    # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† job metadataØŒ Ù†Ø­Ø§ÙˆÙ„ room metadata
    if user_name == "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…":
        try:
            await ctx.connect()
            print("[agent] control plane connected")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© room metadata
            room_metadata = ctx.room.metadata
            if room_metadata:
                print(f"[agent] room metadata Ù…ÙˆØ¬ÙˆØ¯: {room_metadata}")
                metadata = json.loads(room_metadata)
                user_name = metadata.get("username", "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
                full_name = metadata.get("full_name", user_name)
                user_id = metadata.get("user_id")
                mode = metadata.get("mode", "normal")
                voice_name = metadata.get("voice_name", "Aoede")  # ğŸ¤ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª
                print(f"[agent] Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† room: Ø§Ù„Ø§Ø³Ù…={user_name}, Ø§Ù„Ù…Ø¹Ø±Ù={user_id}, Ø§Ù„ÙˆØ¶Ø¹={mode}, Ø§Ù„ØµÙˆØª={voice_name}")
            else:
                print("[agent] Ù„Ø§ ÙŠÙˆØ¬Ø¯ room metadata Ø£ÙŠØ¶Ø§Ù‹")
        except Exception as room_error:
            print(f"[agent] ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© room metadata: {room_error}")
    else:
        # Ø§ÙØªØ­ Ø§ØªØµØ§Ù„ Ø§Ù„ØªØ­ÙƒÙ… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙØªÙˆØ­Ø§Ù‹ Ø¨Ø¹Ø¯
        print(f"[agent] ğŸ” DEBUG: URL={ctx._info.url}")
        print(f"[agent] ğŸ” DEBUG: Room={ctx.room.name}")
        await ctx.connect()
        print("[agent] control plane connected")

    session = AgentSession()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ù…Ø­Ø§Ø¯Ø«Ø© Ø£ÙˆÙ„ÙŠ Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    initial_ctx = ChatContext()
    initial_ctx.add_message(
        role="system", 
        content=f"""Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
- Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„: {full_name or user_name}
- Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_id}
- Ø£Ù†Øª FridayØŒ Ù…Ø³Ø§Ø¹Ø¯ ØµÙˆØªÙŠ Ø°ÙƒÙŠ Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
- Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙØ§Ø¹Ù„ÙŠØ© ÙˆÙ…Ù…ØªØ¹Ø©
- ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ°ÙƒØ± ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªØ³ØªÙƒÙ…Ù„ Ù…Ù† Ø­ÙŠØ« ØªÙˆÙ‚Ù
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø±Ø¯ÙˆØ¯Ùƒ Ù„Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø´Ø®ØµÙŠØ©
- ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø§Ø­ØªÙØ¸ Ø¨Ø³Ø¬Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©"""
    )

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    assistant = Assistant(
        chat_ctx=initial_ctx, 
        user_id=user_id, 
        user_name=full_name or user_name, 
        mode=mode,
        voice_name=voice_name  # ğŸ¤ ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø®ØªØ§Ø±
    )
    
    # ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø­Ø³Ø¨ Ø§Ù„ÙˆØ¶Ø¹
    if mode == "sentences_learning":
        await assistant.load_sentences_progress()
    elif mode == "english_conversation":
        print("[agent] ÙˆØ¶Ø¹ Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª - ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª")
        await assistant.load_podcast_progress()
    else:
        await assistant.load_user_memory()

    print("[agent] starting session for room")
    await session.start(
        room=ctx.room,
        agent=assistant,
        room_input_options=RoomInputOptions(
            # LiveKit Cloud enhanced noise cancellation
            # - If self-hosting, omit this parameter
            # - For telephony applications, use `BVCTelephony` for best results
            video_enabled=True,
            noise_cancellation=noise_cancellation.BVC(),
        ),
    )
    print("[agent] session started")

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶Ø¹
    if mode == "english_conversation":
        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø­Ù…Ù„
        if assistant.podcast_progress and assistant.podcast_progress.get('total_conversations', 0) > 0:
            # Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø§Ø¦Ø¯ - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©
            last_topic = assistant.podcast_progress.get('last_topic', '')
            last_position = assistant.podcast_progress.get('last_position', '')
            total_conversations = assistant.podcast_progress.get('total_conversations', 0)
            
            if last_topic:
                welcome_message = f"Welcome back {full_name or user_name}! Last time we were talking about {last_topic}. {last_position} Would you like to continue that conversation or talk about something new?"
            else:
                welcome_message = f"Hello again {full_name or user_name}! Great to have you back for conversation #{total_conversations + 1}! What would you like to talk about today?"
        else:
            # Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ - Ø£ÙˆÙ„ Ù…Ø­Ø§Ø¯Ø«Ø©
            welcome_message = f"Hello {full_name or user_name}! I'm Friday, your English conversation partner. Let's practice speaking English together in a natural, friendly way. How are you feeling today? What would you like to talk about?"
    elif mode == "sentences_learning":
        # Ø±Ø³Ø§Ù„Ø© Ø®Ø§ØµØ© Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ‚Ø¯Ù…
        welcome_message = f"Ù…Ø±Ø­Ø¨Ø§Ù‹ {full_name or user_name}! Ø£Ù†Ø§ FridayØŒ Ù…Ø¯Ø±Ø³Ùƒ Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©.\n\n"
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø³ÙŠØ§Ù‚
        current_level = getattr(assistant, 'current_level', 1)
        learned_history = getattr(assistant, 'learned_sentences_history', [])
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªÙ‚Ø¯Ù… Ø³Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„
        has_sentences_progress = (
            assistant.sentences_progress and 
            assistant.sentences_progress.get('completed_sentences', 0) > 0
        )
        
        if has_sentences_progress:
            completed = assistant.sentences_progress.get('completed_sentences', 0)
            generated_sentences = assistant.sentences_progress.get('generated_sentences', [])
            actual_total = len(generated_sentences)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…Ù„ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©
            has_incomplete_sentences = completed < actual_total
            
            if has_incomplete_sentences:
                # Ù„Ø§ ØªØ²Ø§Ù„ Ù‡Ù†Ø§Ùƒ Ø¬Ù…Ù„ Ù„Ù… ØªÙƒØªÙ…Ù„
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… current_sentence_index Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† completed
                current_index = assistant.sentences_progress.get('current_sentence_index', completed)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù…Ù„ ÙˆØ¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø¹Ù†Ø§ØµØ± ÙØ§Ø±ØºØ© Ø£Ùˆ Ù…ÙƒØ±Ø±Ø©
                clean_sentences = []
                seen_normalized = set()
                for sentence in generated_sentences:
                    if sentence and sentence.strip():
                        normalized = sentence.lower().replace('.', '').replace(',', '').strip()
                        if normalized not in seen_normalized:
                            clean_sentences.append(sentence.strip())
                            seen_normalized.add(normalized)
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†Ø¸ÙØ©
                if len(clean_sentences) != len(generated_sentences):
                    generated_sentences = clean_sentences
                    await supabase_manager.update_sentences_progress(
                        assistant.user_id,
                        assistant.sentences_session_id,
                        generated_sentences=generated_sentences,
                        total_sentences=len(generated_sentences)
                    )
                    print(f"[agent] ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ù…Ù„ Ù…Ù† {len(assistant.sentences_progress.get('generated_sentences', []))} Ø¥Ù„Ù‰ {len(generated_sentences)}")
                
                # Ø¹Ø¯Ù… Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© - Ø¨Ø¯Ø¡ Ø¨Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
                welcome_message += f"Welcome back! Ù„Ù‚Ø¯ ØªØ¹Ù„Ù…Øª {completed} Ø¬Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©. You're at level {current_level}!"
                welcome_message += "Let's continue with new sentences! Ù„Ù†Ø¨Ø¯Ø£ Ø¨Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©..."
            else:
                # Ø§ÙƒØªÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
                total_learned = len(learned_history)
                welcome_message += f"Welcome back! Great progress! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª {total_learned} Ø¬Ù…Ù„Ø©. You're at level {current_level}!"
                welcome_message += "Let's learn new sentences today! Ù„Ù†ØªØ¹Ù„Ù… Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©..."
        else:
            welcome_message += "Ø§Ù„ÙŠÙˆÙ… Ø³Ù†ØªØ¹Ù„Ù… Ù…Ø¹Ø§Ù‹ Ø¬Ù…Ù„ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙÙŠØ¯Ø©. Ø³Ø£ÙˆÙ„Ø¯ Ù„Ùƒ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø¬Ù…Ù„ØŒ ÙˆØ£Ø¹Ù„Ù…Ùƒ ÙƒÙ„ Ø¬Ù…Ù„Ø©ØŒ ÙˆØ£Ø·Ù„Ø¨ Ù…Ù†Ùƒ ØªÙƒØ±Ø§Ø±Ù‡Ø§. ÙŠÙ…ÙƒÙ†Ùƒ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¬Ù…Ù„ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª!\n\n"
            welcome_message += "Ù‡Ù„ Ø£Ù†Øª Ø¬Ø§Ù‡Ø² Ù„Ù†Ø¨Ø¯Ø£ Ø¨Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŸ"
    else:
        # Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        welcome_message = f"Ù…Ø±Ø­Ø¨Ø§Ù‹ {full_name or user_name}ØŒ Ø§Ø³Ù…ÙŠ FridayØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªÙ‚Ø¯Ù… Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        has_previous_progress = (
            assistant.user_progress and 
            assistant.user_progress.get('words_learned', 0) > 0 and
            assistant.user_progress.get('conversation_history')
        )
        
        if has_previous_progress:
            words_learned = assistant.user_progress.get('words_learned', 0)
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
            conversation_history = assistant.user_progress.get('conversation_history', {})
            last_topic = ""
            
            if conversation_history:
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ø¬Ù„Ø³Ø©
                # Ø¹Ø¯Ù… Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© - Ø¨Ø¯Ø¡ Ø¨Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
                welcome_message += f" Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ø¹ÙˆØ¯ØªÙƒ! Ù„Ù‚Ø¯ ØªØ¹Ù„Ù…Øª {words_learned} ÙƒÙ„Ù…Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†."
                welcome_message += "Ù‡Ù„ ØªØ±ÙŠØ¯:1. Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ù† Ø­ÙŠØ« ØªÙˆÙ‚ÙÙ†Ø§2. Ø£Ù… Ø¨Ø¯Ø¡ Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯Ù‚Ù„ Ù„ÙŠ 'Ù…ØªØ§Ø¨Ø¹Ø©' Ø£Ùˆ 'Ù…ÙˆØ¶ÙˆØ¹ Ø¬Ø¯ÙŠØ¯'."
        else:
            welcome_message += " Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! Ø³Ù†Ø¨Ø¯Ø£ Ø±Ø­Ù„Ø© ØªØ¹Ù„Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ (Nouns)."

    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ø¨Ø± generate_reply
    print(f"[agent] Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ÙŠØ©: {welcome_message}")
    await session.generate_reply(
        instructions=f"""Ù‚Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…:
        "{welcome_message}"
        
        ğŸ”¥ğŸ”¥ğŸ”¥ Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ - ØªÙˆÙ‚Ù Ù‡Ù†Ø§ ØªÙ…Ø§Ù…Ø§Ù‹! ğŸ”¥ğŸ”¥ğŸ”¥
        
        Ø¨Ø¹Ø¯ Ù‚ÙˆÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø£Ø¹Ù„Ø§Ù‡:
        1. ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„ÙƒÙ„Ø§Ù… ØªÙ…Ø§Ù…Ø§Ù‹
        2. Ø§Ù†ØªØ¸Ø± Ø±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        3. Ù„Ø§ ØªØªØ­Ø¯Ø« Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø­ØªÙ‰ ÙŠØ±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        4. Ù„Ø§ ØªØ®ØªØ§Ø± Ù„Ù‡ ÙˆÙ„Ø§ ØªÙØªØ±Ø¶ Ø£ÙŠ Ø´ÙŠØ¡
        5. Ø§ØµÙ…Øª ØªÙ…Ø§Ù…Ø§Ù‹ ÙˆØ§Ù†ØªØ¸Ø±
        
        Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø§Ø³ØªÙ…Ø¹ Ø¨Ø¹Ù†Ø§ÙŠØ© Ù„Ø§Ø®ØªÙŠØ§Ø±Ù‡ Ø«Ù… ØªØ§Ø¨Ø¹ Ø­Ø³Ø¨ Ø§Ø®ØªÙŠØ§Ø±Ù‡ ÙÙ‚Ø·.""",
    )
    
    # âš ï¸ Ù…Ù‡Ù…: Ù„Ø§ Ù†Ø³ØªØ¯Ø¹ÙŠ generate_reply Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§!
    # Ø§Ù„Ø³Ø¨Ø¨: AgentSession Ø³ÙŠØªØ¹Ø§Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ø¹ Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø± Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    # Ø¥Ø°Ø§ Ø§Ø³ØªØ¯Ø¹ÙŠÙ†Ø§ generate_reply Ù‡Ù†Ø§ØŒ Ø³ÙŠØ±Ø³Ù„ AI Ø±Ø³Ø§Ù„Ø© Ø«Ø§Ù†ÙŠØ© ÙÙˆØ±Ø§Ù‹ Ù‚Ø¨Ù„ Ø£Ù† ÙŠØ±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    
    # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬ Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø¹Ù†Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©
    def on_session_end():
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø¹Ù†Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø© (Ù…Ø¹Ø§Ù„Ø¬ Ù…ØªØ²Ø§Ù…Ù†)"""
        import asyncio
        
        async def save_progress():
            try:
                print("[agent] Ø§Ù„Ø¬Ù„Ø³Ø© ØªÙ†ØªÙ‡ÙŠØŒ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
                
                # Ø­ÙØ¸ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø© (daily_stats)
                await assistant.end_session_summary()
                
                # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                await assistant.auto_save_progress()
                
                # Ø­ÙØ¸ Ù…Ù„Ø®Øµ Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø¬Ù„Ø³Ø©
                final_summary = f"Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø© - Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {assistant.session_data.get('current_topic', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}, Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©: {len(assistant.session_data.get('words_discussed', []))}"
                await assistant.save_session_progress(session_summary=final_summary)
                print("[agent] âœ… ØªÙ… Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            except Exception as e:
                print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {e}")
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­ÙØ¸ ÙƒÙ…Ù‡Ù…Ø© ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø©
        asyncio.create_task(save_progress())
    
    # Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    session.on("disconnected", on_session_end)
    
    # Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ø¹Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©
    try:
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        from livekit.agents import UserInputTranscribedEvent, ConversationItemAddedEvent
        
        # Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬ Ù†Ø³Ø® ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        @session.on("user_input_transcribed")
        def on_user_input_transcribed(event: UserInputTranscribedEvent):
            import asyncio
            asyncio.create_task(assistant._on_user_input_transcribed(event))
        
        # Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬ Ø¥Ø¶Ø§ÙØ© Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        @session.on("conversation_item_added")
        def on_conversation_item_added(event: ConversationItemAddedEvent):
            import asyncio
            asyncio.create_task(assistant._on_conversation_item_added(event))
        
        assistant._events_bound = True
        print("[agent] ØªÙ… Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø¨Ù†Ø¬Ø§Ø­ Ù…Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø©")
    except Exception as e:
        print(f"[agent] Ø®Ø·Ø£ ÙÙŠ Ø±Ø¨Ø· Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: {e}")
        print("[agent] Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø¯ÙˆØ±ÙŠ ÙÙ‚Ø·")
    
    # Ø¥Ø¶Ø§ÙØ© Ø­ÙØ¸ Ø¯ÙˆØ±ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ© (ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡)
    import asyncio
    
    async def periodic_save():
        """Ø­ÙØ¸ Ø¯ÙˆØ±ÙŠ Ù„Ù„ØªÙ‚Ø¯Ù… - ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù† Ù„ØªØ¬Ù†Ø¨ Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„ØµÙˆØª"""
        # ØªØ£Ø®ÙŠØ± 60 Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        await asyncio.sleep(60)
        
        while True:
            try:
                await asyncio.sleep(60)  # ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©
                if assistant.session_data.get("current_topic") or assistant.session_data.get("words_discussed"):
                    # Ø¥Ù†Ø´Ø§Ø¡ task Ù…Ù†ÙØµÙ„ Ù„Ø¹Ø¯Ù… Ù…Ù‚Ø§Ø·Ø¹Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    asyncio.create_task(assistant.auto_save_progress())
            except Exception as e:
                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ØµÙ…Øª
                break
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø¯ÙˆØ±ÙŠ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
    asyncio.create_task(periodic_save())
    
    # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© - Ø§Ù„Ù†Ø¸Ø§Ù… Ø³ÙŠØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙ‚Ø·


if __name__ == "__main__":
    agents.cli.run_app(
        agents.WorkerOptions(
            entrypoint_fnc=entrypoint,
            # Ø§Ø³Ù… Ø§Ù„Ø¹Ø§Ù…Ù„ Ù„ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø®Ø§Ø¯Ù… Ù…Ù† Ø¹Ù…Ù„ Dispatch ØµØ±ÙŠØ­ Ù„Ù‡
            agent_name="sci-agent",  # Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ dispatch requests!
            # Ù…Ù†Ø¹ ØªØ¹Ø§Ø±Ø¶ Ù…Ù†ÙØ° Ø®Ø§Ø¯Ù… Ø§Ù„ØµØ­Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ 8081 Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ²
            # 0 ÙŠØ¹Ù†ÙŠ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù†ÙØ° Ø­Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            port=0,
        )
    )